{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "# Non corretto, vedere come fare join su Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_seconds(time_str):\n",
    "    if isinstance(time_str, str):  # Check if the value is a string\n",
    "        if 'µs' in time_str:\n",
    "            return float(time_str.rstrip('µs')) / 1e6\n",
    "        elif 'ms' in time_str:\n",
    "            return float(time_str.rstrip('ms')) / 1000\n",
    "        elif 's' in time_str:\n",
    "            return float(time_str.rstrip('s'))\n",
    "        else:\n",
    "            match = re.match(r'([-+]?\\d*\\.?\\d+) / (\\d+)', time_str)\n",
    "            if match:\n",
    "                return float(match.group(1)) / float(match.group(2))\n",
    "        return float(time_str)  # Return the original value if it's not a string or doesn't contain the expectedunits\n",
    "def convert_cpu_throt(df):\n",
    "    columns_to_convert = df.columns[1:].tolist()\n",
    "    df_appoggio = pd.DataFrame()\n",
    "    for column in columns_to_convert:\n",
    "        df_appoggio[column] = df[column].apply(convert_to_seconds)\n",
    "    return df_appoggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_percentage(cpu_str):\n",
    "    if isinstance(cpu_str, str):\n",
    "        return float(cpu_str.rstrip('%'))\n",
    "    return float(cpu_str)\n",
    "\n",
    "def convert_cpu_usage(df):\n",
    "    columns_to_convert = df.columns[1:].tolist()\n",
    "    df_appoggio = pd.DataFrame()\n",
    "    for column in columns_to_convert:\n",
    "        df_appoggio[column] = df[column].apply(remove_percentage)\n",
    "    return df_appoggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_bytes(mem_str):\n",
    "    if isinstance(mem_str, str):  # Check if the value is a string\n",
    "        if 'kiB' in mem_str:\n",
    "            return float(mem_str.rstrip('KiB')) / 1000\n",
    "        elif 'MiB' in mem_str:\n",
    "            return float(mem_str.rstrip('MiB'))\n",
    "        elif \"GiB\":\n",
    "            return float(mem_str.rstrip('GiB')) * 1000\n",
    "        return float(mem_str)\n",
    "\n",
    "def convert_mem_usage(df):\n",
    "    columns_to_convert = df.columns[1:].tolist()\n",
    "    df_appoggio = pd.DataFrame()\n",
    "    for column in columns_to_convert:\n",
    "        df_appoggio[column] = df[column].apply(convert_to_bytes)\n",
    "    return df_appoggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_folder(folder,filenames,df):\n",
    "    cpu_usage = pd.DataFrame()\n",
    "    cpu_throt = pd.DataFrame()\n",
    "    mem_usage = pd.DataFrame()\n",
    "    con_usage = pd.DataFrame()\n",
    "    net_io = pd.DataFrame()\n",
    "    pod_ready = pd.DataFrame()\n",
    "    res_limits = pd.DataFrame()\n",
    "    restarts = pd.DataFrame()\n",
    "    for file in os.listdir(f'{folder}/Idle'):\n",
    "        if file in filenames:\n",
    "            if file == \"CPUUsage.csv\" :\n",
    "                cpu_usage = pd.concat([cpu_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second dataframe\n",
    "                cpu_usage = pd.concat([cpu_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second datafra\n",
    "                cpu_usage = convert_cpu_usage(cpu_usage)\n",
    "            elif file == \"CPUThrottling.csv\":\n",
    "                cpu_throt = pd.concat([cpu_throt, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])  # Concatenate the first dataframe\n",
    "                cpu_throt = pd.concat([cpu_throt, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second datafra\n",
    "                cpu_throt = convert_cpu_throt(cpu_throt)\n",
    "            elif file == \"MemoryUsage.csv\":\n",
    "                mem_usage = pd.concat([mem_usage, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                mem_usage = pd.concat([mem_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "                mem_usage = convert_mem_usage(mem_usage)\n",
    "            elif file == \"ContainerUsage.csv\":\n",
    "                con_usage = pd.concat([con_usage, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                con_usage = pd.concat([con_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            elif file == \"NetworkIO.csv\":\n",
    "                net_io = pd.concat([net_io, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                net_io = pd.concat([net_io, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            elif file == \"PodReady.csv\":\n",
    "                pod_ready = pd.concat([pod_ready, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                pod_ready = pd.concat([pod_ready, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            elif file == \"ResourceLimits.csv\":\n",
    "                res_limits = pd.concat([res_limits, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                res_limits = pd.concat([res_limits, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            elif file == \"Restarts.csv\":\n",
    "                restarts = pd.concat([restarts, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                restarts = pd.concat([restarts, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            df = pd.concat([df,cpu_usage])\n",
    "            df = pd.concat([df,cpu_throt])\n",
    "            df = pd.concat([df,mem_usage])\n",
    "            df = pd.concat([df,con_usage])\n",
    "            df = pd.concat([df,net_io])\n",
    "            df = pd.concat([df,pod_ready])\n",
    "            df = pd.concat([df,res_limits])\n",
    "            df = pd.concat([df,restarts])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_seconds(time_str):\n",
    "    if isinstance(time_str, str):  # Check if the value is a string\n",
    "        if 'µs' in time_str:\n",
    "            return float(time_str.rstrip('µs')) / 1e6\n",
    "        elif 'ms' in time_str:\n",
    "            return float(time_str.rstrip('ms')) / 1000\n",
    "        elif 's' in time_str:\n",
    "            return float(time_str.rstrip('s'))\n",
    "        else:\n",
    "            match = re.match(r'([-+]?\\d*\\.?\\d+) / (\\d+)', time_str)\n",
    "            if match:\n",
    "                return float(match.group(1)) / float(match.group(2))\n",
    "        return float(time_str)  # Return the original value if it's not a string or doesn't contain the expectedunits\n",
    "def convert_cpu_throt(df):\n",
    "    columns_to_convert = df.columns[1:].tolist()\n",
    "    df_appoggio = pd.DataFrame()\n",
    "    for column in columns_to_convert:\n",
    "        df_appoggio[column] = df[column].apply(convert_to_seconds)\n",
    "    return df_appoggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_percentage(cpu_str):\n",
    "    if isinstance(cpu_str, str):\n",
    "        return float(cpu_str.rstrip('%'))\n",
    "    return float(cpu_str)\n",
    "\n",
    "def convert_cpu_usage(df):\n",
    "    columns_to_convert = df.columns[1:].tolist()\n",
    "    df_appoggio = pd.DataFrame()\n",
    "    for column in columns_to_convert:\n",
    "        df_appoggio[column] = df[column].apply(remove_percentage)\n",
    "    return df_appoggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_bytes(mem_str):\n",
    "    if isinstance(mem_str, str):  # Check if the value is a string\n",
    "        if 'KiB' in mem_str:\n",
    "            return float(mem_str.rstrip('KiB')) / 1000\n",
    "        elif 'MiB' in mem_str:\n",
    "            return float(mem_str.rstrip('MiB'))\n",
    "        elif \"GiB\":\n",
    "            return float(mem_str.rstrip('GiB')) * 1000\n",
    "        return float(mem_str)\n",
    "\n",
    "def convert_mem_usage(df):\n",
    "    columns_to_convert = df.columns[1:].tolist()\n",
    "    df_appoggio = pd.DataFrame()\n",
    "    for column in columns_to_convert:\n",
    "        df_appoggio[column] = df[column].apply(convert_to_bytes)\n",
    "    return df_appoggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_io(mem_str):\n",
    "    if isinstance(mem_str, str):  # Check if the value is a string\n",
    "        if 'kb' in mem_str:\n",
    "            return float(mem_str.rstrip('kb')) / 1000\n",
    "        elif 'Mb' in mem_str:\n",
    "            return float(mem_str.rstrip('Mb'))\n",
    "        elif \"gb\":\n",
    "            return float(mem_str.rstrip('gb')) * 1000\n",
    "        return float(mem_str)\n",
    "\n",
    "def convert_network(df):\n",
    "    columns_to_convert = df.columns[1:].tolist()\n",
    "    df_appoggio = pd.DataFrame()\n",
    "    for column in columns_to_convert:\n",
    "        df_appoggio[column] = df[column].apply(convert_io)\n",
    "    return df_appoggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_folder(folder,filenames,df):\n",
    "    cpu_usage = pd.DataFrame()\n",
    "    cpu_throt = pd.DataFrame()\n",
    "    mem_usage = pd.DataFrame()\n",
    "    con_usage = pd.DataFrame()\n",
    "    net_io = pd.DataFrame()\n",
    "    pod_ready = pd.DataFrame()\n",
    "    res_limits = pd.DataFrame()\n",
    "    restarts = pd.DataFrame()\n",
    "    for file in os.listdir(f'{folder}/Idle'):\n",
    "        if file in filenames:\n",
    "            if file == \"CPUUsage.csv\" :\n",
    "                cpu_usage = pd.concat([cpu_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second dataframe\n",
    "                cpu_usage = pd.concat([cpu_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second datafra\n",
    "                cpu_usage = convert_cpu_usage(cpu_usage)\n",
    "            elif file == \"CPUThrottling.csv\":\n",
    "                cpu_throt = pd.concat([cpu_throt, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])  # Concatenate the first dataframe\n",
    "                cpu_throt = pd.concat([cpu_throt, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second datafra\n",
    "                cpu_throt = convert_cpu_throt(cpu_throt)\n",
    "            elif file == \"MemoryUsage.csv\":\n",
    "                mem_usage = pd.concat([mem_usage, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                mem_usage = pd.concat([mem_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "                mem_usage = convert_mem_usage(mem_usage)\n",
    "            elif file == \"ContainerUsage.csv\":\n",
    "                con_usage = pd.concat([con_usage, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                con_usage = pd.concat([con_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            elif file == \"NetworkIO.csv\":\n",
    "                net_io = pd.concat([net_io, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                net_io = pd.concat([net_io, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "                net_io = convert_network(net_io)\n",
    "            elif file == \"PodReady.csv\":\n",
    "                pod_ready = pd.concat([pod_ready, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                pod_ready = pd.concat([pod_ready, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            elif file == \"ResourceLimits.csv\":\n",
    "                res_limits = pd.concat([res_limits, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                res_limits = pd.concat([res_limits, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            elif file == \"Restarts.csv\":\n",
    "                restarts = pd.concat([restarts, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "                restarts = pd.concat([restarts, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "            df = pd.concat([df,cpu_usage])\n",
    "            df = pd.concat([df,cpu_throt])\n",
    "            df = pd.concat([df,mem_usage])\n",
    "            df = pd.concat([df,con_usage])\n",
    "            print(net_io)\n",
    "            df = pd.concat([df,net_io])\n",
    "            df = pd.concat([df,pod_ready])\n",
    "            df = pd.concat([df,res_limits])\n",
    "            df = pd.concat([df,restarts])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#folders = [\"DDoS Classico\", \"GET Flood\", \"No attacks\", \"Slow DDoS\", \"SYN Flood\"]\n",
    "folders = [\"No attacks\"]\n",
    "filenames = [\"CPUUsage.csv\",\"CPUThrottling.csv\", \"MemoryUsage.csv\",\"ContainerUsage.csv\", \"NetworkIO.csv\", \"PodReady.csv\", \"ResourceLimits.csv\",\"Restarts.csv\"]\n",
    "\n",
    "\n",
    "\n",
    "ddos = pd.DataFrame()\n",
    "get_flood = pd.DataFrame()\n",
    "no_attacks = pd.DataFrame()\n",
    "slow = pd.DataFrame()\n",
    "syn = pd.DataFrame()\n",
    "\n",
    "ddos = read_folder(folders[0],filenames,ddos)\n",
    "get_flood = read_folder(folders[1],filenames,get_flood)\n",
    "no_attacks = read_folder(folders[2],filenames,no_attacks)\n",
    "slow = read_folder(folders[3],filenames,slow)\n",
    "syn = read_folder(folders[0],filenames,syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddos = read_folder(folders[0],filenames,ddos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_usage = convert_cpu_usage(cpu_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_throt = convert_cpu_throt(cpu_throt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_io = convert_network(net_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mem_usage = convert_mem_usage(mem_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_usage.to_csv(\"Completo/CPUUsage.csv\")\n",
    "mem_usage.to_csv(\"Completo/MemoryUsage.csv\")\n",
    "cpu_throt.to_csv(\"Completo/CpuThrottling.csv\")\n",
    "con_usage.to_csv(\"Completo/ContainerUsage.csv\")\n",
    "net_io.to_csv(\"Completo/NetworkIo.csv\")\n",
    "pod_ready.to_csv(\"Completo/PodReady.csv\")\n",
    "res_limits.to_csv(\"Completo/ResourceLimits.csv\")\n",
    "restarts.to_csv(\"Completo/Restarts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(cpu_usage['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folders = [\"DDoS Classico\", \"GET Flood\", \"No attacks\", \"Slow DDoS\", \"SYN Flood\"]\n",
    "filenames = [\"CPUUsage.csv\",\"CPUThrottling.csv\", \"MemoryUsage.csv\",\"ContainerUsage.csv\", \"NetworkIO.csv\", \"PodReady.csv\", \"ResourceLimits.csv\",\"Restarts.csv\"]\n",
    "\n",
    "\n",
    "\n",
    "ddos = pd.DataFrame()\n",
    "get_flood = pd.DataFrame()\n",
    "no_attacks = pd.DataFrame()\n",
    "slow = pd.DataFrame()\n",
    "syn = pd.DataFrame()\n",
    "\n",
    "ddos = read_folder(folders[0],filenames,ddos)\n",
    "get_flood = read_folder(folders[1],filenames,get_flood)\n",
    "no_attacks = read_folder(folders[2],filenames,no_attacks)\n",
    "slow = read_folder(folders[3],filenames,slow)\n",
    "syn = read_folder(folders[0],filenames,syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m folders \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDDoS Classico\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET Flood\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo attacks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSlow DDoS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSYN Flood\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate through each folder\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m cpu_usage \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      6\u001b[0m cpu_throt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      7\u001b[0m mem_usage \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "folders = [\"DDoS Classico\", \"GET Flood\", \"No attacks\", \"Slow DDoS\", \"SYN Flood\"]\n",
    "\n",
    "\n",
    "# Iterate through each folder\n",
    "cpu_usage = pd.DataFrame()\n",
    "cpu_throt = pd.DataFrame()\n",
    "mem_usage = pd.DataFrame()\n",
    "con_usage = pd.DataFrame()\n",
    "net_io = pd.DataFrame()\n",
    "pod_ready = pd.DataFrame()\n",
    "res_limits = pd.DataFrame()\n",
    "restarts = pd.DataFrame()\n",
    "\n",
    "for folder in folders:\n",
    "    # Load the files into separate dataframes\n",
    "    for file in os.listdir(f'{folder}/Idle'):\n",
    "        if file == \"CPUUsage.csv\" :\n",
    "            file_name = file.split('.')[0]  # Extract the file name without extension\n",
    "            cpu_usage = pd.concat([cpu_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second dataframe\n",
    "            cpu_usage = pd.concat([cpu_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second datafra\n",
    "        elif file == \"CPUThrottling.csv\":\n",
    "            file_name = file.split('.')[0]  # Extract the file name without extension\n",
    "            cpu_throt = pd.concat([cpu_throt, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])  # Concatenate the first dataframe\n",
    "            cpu_throt = pd.concat([cpu_throt, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second datafra\n",
    "        elif file == \"MemoryUsage.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            mem_usage = pd.concat([mem_usage, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            mem_usage = pd.concat([mem_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"ContainerUsage.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            con_usage = pd.concat([con_usage, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            con_usage = pd.concat([con_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"NetworkIO.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            net_io = pd.concat([net_io, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            net_io = pd.concat([net_io, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"PodReady.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            pod_ready = pd.concat([pod_ready, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            pod_ready = pd.concat([pod_ready, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"ResourceLimits.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            res_limits = pd.concat([res_limits, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            res_limits = pd.concat([res_limits, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"Restarts.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            restarts = pd.concat([restarts, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            restarts = pd.concat([restarts, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_usage = convert_cpu_usage(cpu_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_throt = convert_cpu_throt(cpu_throt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_io = convert_network(net_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mem_usage = convert_mem_usage(mem_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(cpu_usage['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folders = [\"DDoS Classico\", \"GET Flood\", \"No attacks\", \"Slow DDoS\", \"SYN Flood\"]\n",
    "\n",
    "\n",
    "# Iterate through each folder\n",
    "cpu_usage = pd.DataFrame()\n",
    "cpu_throt = pd.DataFrame()\n",
    "mem_usage = pd.DataFrame()\n",
    "con_usage = pd.DataFrame()\n",
    "net_io = pd.DataFrame()\n",
    "pod_ready = pd.DataFrame()\n",
    "res_limits = pd.DataFrame()\n",
    "restarts = pd.DataFrame()\n",
    "\n",
    "for folder in folders:\n",
    "    # Load the files into separate dataframes\n",
    "    for file in os.listdir(f'{folder}/Idle'):\n",
    "        if file == \"CPUUsage.csv\" :\n",
    "            file_name = file.split('.')[0]  # Extract the file name without extension\n",
    "            cpu_usage = pd.concat([cpu_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second dataframe\n",
    "            cpu_usage = pd.concat([cpu_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second datafra\n",
    "        elif file == \"CPUThrottling.csv\":\n",
    "            file_name = file.split('.')[0]  # Extract the file name without extension\n",
    "            cpu_throt = pd.concat([cpu_throt, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])  # Concatenate the first dataframe\n",
    "            cpu_throt = pd.concat([cpu_throt, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])  # Concatenate the second datafra\n",
    "        elif file == \"MemoryUsage.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            mem_usage = pd.concat([mem_usage, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            mem_usage = pd.concat([mem_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"ContainerUsage.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            con_usage = pd.concat([con_usage, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            con_usage = pd.concat([con_usage, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"NetworkIO.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            net_io = pd.concat([net_io, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            net_io = pd.concat([net_io, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"PodReady.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            pod_ready = pd.concat([pod_ready, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            pod_ready = pd.concat([pod_ready, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"ResourceLimits.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            res_limits = pd.concat([res_limits, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            res_limits = pd.concat([res_limits, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])\n",
    "        elif file == \"Restarts.csv\":\n",
    "            file_name = file.split('.')[0]\n",
    "            restarts = pd.concat([restarts, pd.read_csv(f'{folder}/Idle/{file}', index_col=0)])\n",
    "            restarts = pd.concat([restarts, pd.read_csv(f'{folder}/Load/{file}', index_col=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
